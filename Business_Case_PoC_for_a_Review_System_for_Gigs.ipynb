{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u57Sjt6vfG4z"
      },
      "source": [
        "# Business Case - PoC for a Review System for Gigs\n",
        "___\n",
        "### Overview\n",
        "This is a business case for creating a rating chatbot for an imaginary gig platform called gig-services.com, which is meant to test programming skills as well as business mindedness.\n",
        "\n",
        "You have 45 minutes to create:\n",
        "\n",
        "1. A bulleted list with 5-10 suggestions on what might improve the general review system and why. The bulleted list should be in it's own cell in the notebook.\n",
        "2. Create a colab notebook that demonstrates the rating chatbot. It does not need to be fully functional but rather work as a proof that the idea could work.\n",
        "\n",
        "Then you will have 5 minutes to present your bullet points as well as demonstrate the chatbot.\n",
        "\n",
        "This will be followed by 5-10 minutes of questions.\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "## Case\n",
        "___\n",
        "#### Company\n",
        "A gig economy platform called gig-services.com allows freelancers publish their services such as web design, art creation and marketing services.\n",
        "\n",
        "Businesses can search among the freelancers and hire them on a gig basis.\n",
        "\n",
        "After a gig the business can leave a review for the freelancer to help other businesses make better decisions.\n",
        "\n",
        "#### Problem\n",
        "When leaving reviews, all businesses just tend to give 5 star all the time, which makes it difficult to know how high quality a gig is.\n",
        "\n",
        "A gig buyer said the following:\n",
        "```\n",
        "Quality can vary massively depending on the freelancer, and there is no good way to know how good they are without trying out their services.\n",
        "Some are very good and definetly underpriced, but sometimes I have been negatively surprised.\n",
        "\n",
        "Most freelancer has 5 star rating only, which makes it a useless metric.\n",
        "\n",
        "With that said, I almost always give five stars, cause it's just easier, and giving a freelancer less than 5 stars feels like you are destroying their perfect rating.\n",
        "So I only give less than 5 stars if it was really really bad, or I abstain from leaving a review at all.\n",
        "```\n",
        "\n",
        "A freelancer said the following:\n",
        "```\n",
        "A lot of buyers turn out to be very difficult to work with, and sometimes ask for more work and revisions that was not originally included in the gig.\n",
        "\n",
        "I feel like I have to simply accept doing the extra work then or I will get a bad review. Alternatively I have to cancel the contract, but then I dont get paid.\n",
        "\n",
        "A bad review hurts my near perfect score, and I worry it will give me fewer gigs in the future, but the difference between a good and a bad client is so huge and it can make my job very stressful.\n",
        "```\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "#### Assignment\n",
        "Your task is to design a new review system that utilizes a ChatGPT powered chatbot to improve the rating system for giving ratings to freelancers gigs.\n",
        "\n",
        "The chatbot would pop up for the buyer after they are have approved delivery of a gig, and should lead to a final score.\n",
        "\n",
        "You have complete freedom in how the chatbot should work. The questions can be prewritten, AI generated or a mix. Further you can decide how long the chat conversations should be, and how the final score for the review is made.\n",
        "\n",
        "In addition to the chatbot, you should write a bulleted list with 5-10 ideas or suggestions that may improve the general review system. These ideas can be related to the chatbot, but does not have to be.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "#### Resources\n",
        "You are free to use any tools, including ChatGPT. Here is an OpenAI API key that can be used: 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\n",
        "\n",
        "Below there is a cell showing how the review system works currently, and below that it are two cells that shows how to install openai and use the ChatGPT API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YefEDx_rw3up"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9QWz2GzVfYg"
      },
      "outputs": [],
      "source": [
        "# This is the code currently used by the platform to create ratings.\n",
        "\n",
        "\n",
        "questions = [\n",
        "    \"To what extent did the gig live up to your expectations?\",\n",
        "    \"To what extent was the gig good value for the cost?\"\n",
        "]\n",
        "\n",
        "def get_score_of_question(question):\n",
        "    \"\"\"Prompt the user for a score between 1 and 5 for a given question and return it.\"\"\"\n",
        "    while True:\n",
        "        print(question)\n",
        "        score = input()\n",
        "        try:\n",
        "            score_int = int(score)\n",
        "            if 0 < score_int < 6:\n",
        "                return score_int\n",
        "            else:\n",
        "                print(\"Please enter a number between 1-5.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a valid integer.\")\n",
        "\n",
        "expectation_score = get_score_of_question(questions[0])\n",
        "value_score = get_score_of_question(questions[1])\n",
        "final_score = (expectation_score + value_score) / 2\n",
        "\n",
        "final_answer = f\"\"\"Thank you. Based on what you have shared with me, I suggest the following scores:\n",
        "\n",
        "The gig lived up to my expectations: {expectation_score} / 5\n",
        "The gig was great value for money: {value_score} / 5\n",
        "\n",
        "Final score is: {final_score} / 5\"\"\"\n",
        "\n",
        "print(final_answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IxYOMNu31Dx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXGp5vQh31Gp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALEHadTZ31JI"
      },
      "outputs": [],
      "source": [
        "Incentivize Detailed Feedback:\n",
        "Offer small incentives, such as discounts or credits, for buyers who provide detailed and constructive feedback.\n",
        "\n",
        "Anonymous Feedback Option:\n",
        "Allow buyers to provide feedback anonymously to encourage honest opinions without fear of repercussions.\n",
        "\n",
        "Skill-Specific Ratings:\n",
        "Implement skill-specific ratings to provide freelancers with insights into their strengths and areas for improvement.\n",
        "\n",
        "Structured Templates:\n",
        "Provide buyers with structured templates for common types of gigs to streamline the feedback process.\n",
        "\n",
        "Machine Learning Analysis:\n",
        "Implement machine learning algorithms to analyze patterns in feedback and offer personalized improvement suggestions to freelancers.\n",
        "\n",
        "Community Forums:\n",
        "Establish community forums where freelancers can discuss and learn from the feedback provided by clients.\n",
        "\n",
        "Responsive Resolution System:\n",
        "Develop a responsive system to address any negative feedback, allowing freelancers to resolve issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cPChyAB31L4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLda_nkm31Oa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyEBCUK731Qd",
        "outputId": "7623761d-d699-472a-932d-2f9e0d49d7a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxq3xzy9WTuR"
      },
      "outputs": [],
      "source": [
        "# We need to install openai to use ChatGPT\n",
        "#!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt727x9Q0RHr",
        "outputId": "e155655b-9d7b-4f0c-f9da-7a439a310b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sVt__alWYKg"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# This cell demonstrates how to query ChatGPT and print the response.\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=''\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is 1+1?\"},\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4hK1ZK8xHnr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUJZIY37xKus"
      },
      "outputs": [],
      "source": [
        "#my 1  (  # Your logic to combine user and chatbot feedback and calculate a final score\n",
        "    # Example: Average the scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "oBRzOv3dxK1Y",
        "outputId": "b85dfc52-481b-43e0-8bbe-cfc1b689c8ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your rating for the freelancer's gig: 5\n",
            "Please provide feedback on the freelancer's gig: 5\n"
          ]
        },
        {
          "ename": "InvalidRequestError",
          "evalue": "The model `text-davinci-002` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cd63af3d7453>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-cd63af3d7453>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0muser_feedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please provide your rating for the freelancer's gig: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mchatbot_feedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_user_feedback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_final_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_feedback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchatbot_feedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Final Score: {final_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd63af3d7453>\u001b[0m in \u001b[0;36mget_user_feedback\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_user_feedback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mgig_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please provide feedback on the freelancer's gig: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mchatbot_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatbot_interaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgig_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchatbot_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd63af3d7453>\u001b[0m in \u001b[0;36mchatbot_interaction\u001b[0;34m(gig_description)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchatbot_interaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgig_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Rate the freelancer's gig: {gig_description}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mchatbot_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchatbot_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd63af3d7453>\u001b[0m in \u001b[0;36mgenerate_review\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'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'\u001b[0m  \u001b[0;31m# Replace with your actual OpenAI API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-002\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Use the appropriate engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: The model `text-davinci-002` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations"
          ]
        }
      ],
      "source": [
        "\n",
        "import openai\n",
        "\n",
        "\n",
        "def generate_review(prompt):\n",
        "    openai.api_key = ''  # Replace with your actual OpenAI API key\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\",  # Use the appropriate engine\n",
        "        prompt=prompt,\n",
        "        max_tokens=150,  # Adjust as needed\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,  # Adjust for creativity vs accuracy\n",
        "    )\n",
        "\n",
        "\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def chatbot_interaction(gig_description):\n",
        "    prompt = f\"Rate the freelancer's gig: {gig_description}\\n\"\n",
        "    chatbot_response = generate_review(prompt)\n",
        "    return chatbot_response\n",
        "\n",
        "def get_user_feedback():\n",
        "    gig_description = input(\"Please provide feedback on the freelancer's gig: \")\n",
        "    chatbot_response = chatbot_interaction(gig_description)\n",
        "    return chatbot_response\n",
        "\n",
        "def calculate_final_score(user_feedback, chatbot_feedback):\n",
        "    # Your logic to combine user and chatbot feedback and calculate a final score\n",
        "    # Example: Average the scores\n",
        "    final_score = (user_feedback + chatbot_feedback) / 2\n",
        "    return final_score\n",
        "\n",
        "def main():\n",
        "    user_feedback = float(input(\"Please provide your rating for the freelancer's gig: \"))\n",
        "    chatbot_feedback = float(get_user_feedback())\n",
        "    final_score = calculate_final_score(user_feedback, chatbot_feedback)\n",
        "    print(f\"Final Score: {final_score}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7HjFl_pxK4Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4Ov-fxu0Z73"
      },
      "outputs": [],
      "source": [
        "#my2    # For example, you can use sentiment analysis or keyword matching\n",
        "    # For simplicity, let's assume the review is a numeric score between 1 and 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlCjpw-y0Z-m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHCwmFbrxXnv",
        "outputId": "7466a88b-0692-445e-db51-e705a94dd174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unable to determine the review score. Please review manually.\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = ''\n",
        "\n",
        "def generate_review(prompt):\n",
        "    # Using OpenAI GPT-3.5 API to generate a review based on the given prompt\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-002\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=150  # You can adjust the length of the generated text\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_review_score(review):\n",
        "    # You can implement your own logic to extract and calculate a score from the generated review\n",
        "    # For example, you can use sentiment analysis or keyword matching\n",
        "    # For simplicity, let's assume the review is a numeric score between 1 and 5\n",
        "    try:\n",
        "        score = float(review)\n",
        "        if 1 <= score <= 5:\n",
        "            return score\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    # If the score extraction fails, you can ask the user for clarification or handle it in another way\n",
        "    return None\n",
        "\n",
        "def main():\n",
        "    # Simulate the approval of a gig and trigger the chatbot\n",
        "    gig_description = \"Describe the gig here\"  # Replace with your gig details\n",
        "    prompt = f\"Provide a review for the freelancer who delivered the following gig:\\n\\\"{gig_description}\\\"\\n\\nReview: \"\n",
        "\n",
        "    # Generate a review using the chatbot\n",
        "    review = generate_review(prompt)\n",
        "\n",
        "    # Get the review score\n",
        "    score = get_review_score(review)\n",
        "\n",
        "    if score is not None:\n",
        "        print(f\"The generated review is: {review}\")\n",
        "        print(f\"The calculated score is: {score}\")\n",
        "        # Store the score in your database or use it as needed\n",
        "    else:\n",
        "        print(\"Unable to determine the review score. Please review manually.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9prrgmay1Z4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCSsONEby1ci"
      },
      "outputs": [],
      "source": [
        "#my3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYPgyC31y1e5"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = ''\n",
        "\n",
        "def generate_review(prompt):\n",
        "    # Using OpenAI GPT-3.5 API to generate a review based on the given prompt\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=150  # You can adjust the length of the generated text\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def get_review_score(review):\n",
        "    # You can implement your own logic to extract and calculate a score from the generated review\n",
        "    # For example, you can use sentiment analysis or keyword matching\n",
        "    # For simplicity, let's assume the review is a numeric score between 1 and 5\n",
        "    try:\n",
        "        score = float(review)\n",
        "        if 1 <= score <= 5:\n",
        "            return score\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    # If the score extraction fails, you can ask the user for clarification or handle it in another way\n",
        "    return None\n",
        "\n",
        "def main():\n",
        "    # Simulate the approval of a gig and trigger the chatbot\n",
        "    gig_description = \"Describe the gig here\"  # Replace with your gig details\n",
        "    prompt = f\"Provide a review for the freelancer who delivered the following gig:\\n\\\"{gig_description}\\\"\\n\\nReview: \"\n",
        "\n",
        "    # Generate a review using the chatbot\n",
        "    review = generate_review(prompt)\n",
        "\n",
        "    # Get the review score\n",
        "    score = get_review_score(review)\n",
        "\n",
        "    if score is not None:\n",
        "        print(f\"The generated review is: {review}\")\n",
        "        print(f\"The calculated score is: {score}\")\n",
        "        # Store the score in your database or use it as needed\n",
        "    else:\n",
        "        print(\"Unable to determine the review score. Please review manually.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTxQqV4-xK9o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
